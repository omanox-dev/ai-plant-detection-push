# .env.example â€” redacted example of required env variables
# Copy this to `.env` and fill in real values before running locally

# Direct Gemini / Generative Language endpoint
LLM_URL=https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-latest:generateContent
LLM_API_KEY=YOUR_GENERATIVE_LANGUAGE_API_KEY

# Enable or disable AI takeover (set to false to use only ML models)
ENABLE_AI_TAKEOVER=true

# Enable or disable local ML model inference. When `ML_ENABLED=false`,
# the application should skip local model inference and rely on LLMs or
# other fallbacks. Set to `true` to enable ML model usage.
ML_ENABLED=true

# Threshold (percent) below which the backend will call the LLM fallback
AI_FALLBACK_THRESHOLD=99

# Optional: Supabase function fallback (if you prefer to call the Supabase Edge function)
#SUPABASE_CHATBOT_URL=https://<your-supabase-project>.functions.supabase.co/plant-chatbot
#SUPABASE_API_KEY=YOUR_SUPABASE_ANON_OR_SERVICE_KEY
